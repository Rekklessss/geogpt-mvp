ubuntu@ip-172-31-68-27:/opt/geogpt-rag/app/geogpt-rag$ # 1. Pull the enhanced test suite
cd /opt/geogpt-rag/app/geogpt-rag
git pull origin main

# 2. Make the enhanced test script executable
chmod +x run-comprehensive-tests.sh

# 3. Run the comprehensive test suite (this will take 10-15 minutes)
./run-comprehensive-tests.sh
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 9.25 KiB | 9.25 MiB/s, done.
From https://github.com/Rekklessss/geogpt-mvp
 * branch            main       -> FETCH_HEAD
   c75b8e4..18f65c4  main       -> origin/main
Updating c75b8e4..18f65c4
Fast-forward
 geogpt-rag/run-comprehensive-tests.sh | 704 ++++++++++++++++++++++++++++++++++++++++++++++++++++------------
 1 file changed, 580 insertions(+), 124 deletions(-)
[2025-07-04 14:37:28] üíª Running on local machine
[2025-07-04 14:37:28] üß™ Starting GeoGPT-RAG Enhanced Comprehensive Test Suite
[2025-07-04 14:37:28] ========================================================
[2025-07-04 14:37:28] INFO: Environment: LOCAL
[2025-07-04 14:37:28] INFO: CUDA 12.8 Compatibility & Complete RAG Pipeline Validation
[2025-07-04 14:37:28] üê≥ Phase 1: Docker Environment Validation
[2025-07-04 14:37:28] TEST: Checking Docker containers status...
[2025-07-04 14:37:28] SUCCESS: ‚úÖ Docker containers are running
NAME             IMAGE                   COMMAND                  SERVICE      CREATED          STATUS                    PORTS
geogpt-rag-api   geogpt-rag-geogpt-rag   "/opt/nvidia/nvidia_‚Ä¶"   geogpt-rag   10 minutes ago   Up 10 minutes (healthy)   0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp
[2025-07-04 14:37:29] üîß Phase 2: Dependency & CUDA Validation
[2025-07-04 14:37:29] TEST: Testing Python 3.12 and dependencies...
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-07-04 14:37:40.300448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-04 14:37:40.515594: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-04 14:37:40.581058: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-04 14:37:41.031009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-04 14:37:43.085967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import DistributionNotFound, get_distribution
‚úÖ Python: 3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0]
‚úÖ PyTorch: 2.4.0+cu121
‚úÖ Transformers: 4.53.0
‚úÖ Sentence Transformers: 5.0.0
‚úÖ pymilvus: 2.4.10
‚úÖ TensorFlow: 2.17.0
üéâ All dependencies validated!
[2025-07-04 14:37:48] SUCCESS: ‚úÖ All dependencies validated
[2025-07-04 14:37:48] TEST: Testing CUDA 12.8 compatibility...
üî• PyTorch CUDA available: True
üì± CUDA device count: 1
üíæ CUDA device name: NVIDIA A10G
üéØ CUDA version: 12.1
‚úÖ GPU tensor operations working: torch.Size([100, 100])
[2025-07-04 14:37:50] SUCCESS: ‚úÖ CUDA compatibility verified
[2025-07-04 14:37:50] SUCCESS: ‚úÖ Phase 2 completed: Dependencies and CUDA validated
[2025-07-04 14:37:50] üåê Phase 3: API Endpoint Testing
[2025-07-04 14:37:50] TEST: Waiting for API to be ready...
[2025-07-04 14:38:00] TEST: Testing health endpoint...
[2025-07-04 14:38:00] SUCCESS: ‚úÖ Health endpoint responding (200 OK)
{
  "status": "healthy",
  "collection": "geodocs",
  "components": {
    "embeddings": "operational",
    "reranking": "operational",
    "vector_store": "operational",
    "text_splitter": "operational"
  }
}
[2025-07-04 14:38:00] TEST: Testing root endpoint...
[2025-07-04 14:38:00] SUCCESS: ‚úÖ Root endpoint responding (200 OK)
{
  "message": "GeoGPT-RAG API",
  "docs": "/docs"
}
[2025-07-04 14:38:00] SUCCESS: ‚úÖ Phase 3 completed: API endpoints validated
[2025-07-04 14:38:00] ü§ñ Phase 4: SageMaker Integration Testing
[2025-07-04 14:38:00] TEST: Testing SageMaker endpoint connectivity and LLM generation...
[2025-07-04 14:38:00] WARNING: ‚ö†Ô∏è  SageMaker endpoint returned 500 (may need documents in KB)
[2025-07-04 14:38:00] TEST: Testing SageMaker endpoint status...
‚úÖ SageMaker endpoint direct connection successful
‚úÖ Response status: 200
[2025-07-04 14:38:18] SUCCESS: ‚úÖ Phase 4 completed: SageMaker integration tested
[2025-07-04 14:38:18] üîó Phase 5: End-to-End RAG Pipeline Testing
[2025-07-04 14:38:18] TEST: Creating comprehensive test document...
[2025-07-04 14:38:18] TEST: Testing complete RAG pipeline: Upload ‚Üí Embed ‚Üí Store ‚Üí Retrieve ‚Üí Generate...
[2025-07-04 14:38:18] INFO: Step 1: Document upload...
[2025-07-04 14:38:18] SUCCESS: ‚úÖ Phase 5 completed: End-to-End RAG pipeline tested
[2025-07-04 14:38:18] üî¢ Phase 6: Vector Store & Embedding Quality Testing
[2025-07-04 14:38:18] TEST: Testing embedding generation quality...
Traceback (most recent call last):
  File "<string>", line 4, in <module>
  File "/app/app/embeddings.py", line 6, in <module>
    from .models.embedding import EmbeddingModel
ImportError: attempted relative import with no known parent package
[2025-07-04 14:38:20] TEST: Testing vector store operations...
/app/app/kb.py:20: LangChainDeprecationWarning: Importing Milvus from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import Milvus

with new imports of:

>> from langchain_community.vectorstores import Milvus
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.vectorstores import Milvus
/usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import DistributionNotFound, get_distribution
Traceback (most recent call last):
  File "<string>", line 4, in <module>
  File "/app/app/kb.py", line 23, in <module>
    from .embeddings import GeoEmbeddings
ImportError: attempted relative import with no known parent package
[2025-07-04 14:38:22] SUCCESS: ‚úÖ Phase 6 completed: Vector store and embeddings tested
[2025-07-04 14:38:22] üéØ Phase 7: Reranking & Relevance Testing
[2025-07-04 14:38:22] TEST: Testing reranking functionality...
Traceback (most recent call last):
  File "<string>", line 4, in <module>
  File "/app/app/reranking.py", line 5, in <module>
    from .models.reranker import RerankerModel
ImportError: attempted relative import with no known parent package
[2025-07-04 14:38:22] SUCCESS: ‚úÖ Phase 7 completed: Reranking tested
[2025-07-04 14:38:22] üìÑ Phase 8: Document Processing Pipeline Testing
[2025-07-04 14:38:22] TEST: Testing text splitting and chunking...
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-07-04 14:38:26.916981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-04 14:38:26.936983: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-04 14:38:26.943204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-04 14:38:26.958172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-04 14:38:27.924907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "<string>", line 4, in <module>
  File "/app/app/utils/__init__.py", line 8, in <module>
    from .parsers import TextSplitter, split_text
  File "/app/app/utils/parsers.py", line 28, in <module>
    from ..config import BERT_PATH, MAX_SIZE
ImportError: attempted relative import beyond top-level package
[2025-07-04 14:38:30] SUCCESS: ‚úÖ Phase 8 completed: Document processing tested
[2025-07-04 14:38:30] ‚ö° Phase 9: Performance Benchmarking
[2025-07-04 14:38:30] TEST: Testing API response times and throughput...
üìä Performance Benchmarks:
‚è±Ô∏è  Health Endpoint: avg=1.52ms, min=1.20ms, max=2.57ms
‚è±Ô∏è  Root Endpoint: avg=1.28ms, min=1.24ms, max=1.36ms

üöÄ Concurrent Request Test:
‚úÖ Concurrent requests: 100% success rate in 0.01s
‚úÖ Health endpoint performance: GOOD
[2025-07-04 14:38:30] TEST: Checking container resource usage...
üìä Current Resource Usage:
CONTAINER      CPU %     MEM USAGE / LIMIT   MEM %
ed4a80e27177   0.11%     2.103GiB / 14GiB    15.02%
[2025-07-04 14:38:32] SUCCESS: ‚úÖ Phase 9 completed: Performance benchmarked
[2025-07-04 14:38:32] üõ°Ô∏è Phase 10: Error Handling & Edge Case Testing
[2025-07-04 14:38:32] TEST: Testing malformed requests and error handling...
[2025-07-04 14:38:32] SUCCESS: ‚úÖ Malformed JSON handled correctly
[2025-07-04 14:38:32] SUCCESS: ‚úÖ Missing fields handled correctly
[2025-07-04 14:38:32] SUCCESS: ‚úÖ Invalid file upload handled correctly
[2025-07-04 14:38:32] SUCCESS: ‚úÖ Phase 10 completed: Error handling tested
[2025-07-04 14:38:32] üß™ Phase 11: PyTest Unit Test Suite
[2025-07-04 14:38:32] TEST: Running comprehensive unit tests...
============================================ test session starts =============================================
platform linux -- Python 3.12.3, pytest-8.3.3, pluggy-1.6.0 -- /usr/bin/python
cachedir: .pytest_cache
rootdir: /app
plugins: anyio-4.9.0, asyncio-0.23.8, langsmith-0.3.45, timeout-2.3.1, mock-3.14.0, cov-5.0.0
asyncio: mode=Mode.STRICT
collected 56 items

tests/test_api.py::TestRootEndpoints::test_root_endpoint PASSED                                        [  1%]
tests/test_api.py::TestRootEndpoints::test_health_endpoint_healthy PASSED                              [  3%]
tests/test_api.py::TestRootEndpoints::test_health_endpoint_unhealthy PASSED                            [  5%]
tests/test_api.py::TestFileUpload::test_upload_pdf_success FAILED                                      [  7%]
tests/test_api.py::TestFileUpload::test_upload_text_success FAILED                                     [  8%]
tests/test_api.py::TestFileUpload::test_upload_no_file PASSED                                          [ 10%]
tests/test_api.py::TestFileUpload::test_upload_empty_file FAILED                                       [ 12%]
tests/test_api.py::TestFileUpload::test_upload_processing_error FAILED                                 [ 14%]
tests/test_api.py::TestFileUpload::test_upload_kb_not_initialized PASSED                               [ 16%]
tests/test_api.py::TestQueryEndpoints::test_query_success PASSED                                       [ 17%]
tests/test_api.py::TestQueryEndpoints::test_query_no_results PASSED                                    [ 19%]
tests/test_api.py::TestQueryEndpoints::test_retrieve_success FAILED                                    [ 21%]
tests/test_api.py::TestQueryEndpoints::test_query_invalid_parameters PASSED                            [ 23%]
tests/test_api.py::TestQueryEndpoints::test_query_missing_query PASSED                                 [ 25%]
tests/test_api.py::TestQueryEndpoints::test_query_processing_error PASSED                              [ 26%]
tests/test_api.py::TestQueryEndpoints::test_query_kb_not_initialized PASSED                            [ 28%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_success FAILED                       [ 30%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_error PASSED                         [ 32%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_kb_not_initialized PASSED            [ 33%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_success FAILED                               [ 35%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_no_collection FAILED                         [ 37%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_error FAILED                                 [ 39%]
tests/test_api.py::TestErrorHandling::test_invalid_endpoint PASSED                                     [ 41%]
tests/test_api.py::TestErrorHandling::test_invalid_method PASSED                                       [ 42%]
tests/test_api.py::TestErrorHandling::test_malformed_json PASSED                                       [ 44%]
tests/test_api.py::TestIntegration::test_upload_and_query_workflow FAILED                              [ 46%]
tests/test_api.py::test_app_lifespan PASSED                                                            [ 48%]
tests/test_api.py::TestPerformance::test_health_endpoint_response_time PASSED                          [ 50%]
tests/test_api.py::TestPerformance::test_concurrent_queries PASSED                                     [ 51%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_pytorch_cuda_version PASSED              [ 53%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_tensorflow_gpu_access PASSED             [ 55%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_transformers_device_detection PASSED     [ 57%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_embeddings_gpu_compatibility SKIPPED     [ 58%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_reranking_gpu_compatibility FAILED       [ 60%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_model_cache_directories PASSED           [ 62%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_dependency_versions PASSED               [ 64%]
tests/test_cuda_compatibility.py::TestPerformanceWithGPU::test_tensor_operations_performance PASSED    [ 66%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_success PASSED [ 67%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_with_credentials PASSED [ 69%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_boto3_missing PASSED [ 71%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_no_credentials PASSED [ 73%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_prepare_request_payload PASSED       [ 75%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_huggingface_format PASSED [ 76%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_dict_format PASSED    [ 78%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_malformed_json PASSED [ 80%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_success PASSED              [ 82%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_client_error FAILED         [ 83%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_general_error FAILED        [ 85%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_test_connection_success FAILED       [ 87%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_sagemaker_response_success PASSED [ 89%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_sagemaker_response_no_endpoint PASSED [ 91%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_llm_response_sagemaker_provider PASSED [ 92%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_llm_response_openai_provider PASSED [ 94%]
tests/test_sagemaker_integration.py::TestSageMakerRAGIntegration::test_full_rag_query_with_sagemaker PASSED [ 96%]
tests/test_sagemaker_integration.py::TestSageMakerAPIIntegration::test_api_query_with_sagemaker PASSED [ 98%]
tests/test_sagemaker_integration.py::TestSageMakerAPIIntegration::test_api_query_sagemaker_not_configured PASSED [100%]

================================================== FAILURES ==================================================
___________________________________ TestFileUpload.test_upload_pdf_success ___________________________________
tests/test_api.py:142: in test_upload_pdf_success
    assert response.status_code == status.HTTP_200_OK
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
E    +  and   200 = status.HTTP_200_OK
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.pdf'
__________________________________ TestFileUpload.test_upload_text_success ___________________________________
tests/test_api.py:162: in test_upload_text_success
    assert response.status_code == status.HTTP_200_OK
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
E    +  and   200 = status.HTTP_200_OK
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
___________________________________ TestFileUpload.test_upload_empty_file ____________________________________
tests/test_api.py:177: in test_upload_empty_file
    assert response.status_code == status.HTTP_400_BAD_REQUEST
E   assert 503 == 400
E    +  where 503 = <Response [503 Service Unavailable]>.status_code
E    +  and   400 = status.HTTP_400_BAD_REQUEST
________________________________ TestFileUpload.test_upload_processing_error _________________________________
tests/test_api.py:194: in test_upload_processing_error
    assert "Error processing file" in data["detail"]
E   assert 'Error processing file' in "Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'"
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
__________________________________ TestQueryEndpoints.test_retrieve_success __________________________________
tests/test_api.py:282: in test_retrieve_success
    assert data["retrieval_count"] == 2
E   KeyError: 'retrieval_count'
___________________________ TestCollectionManagement.test_drop_collection_success ____________________________
tests/test_api.py:346: in test_drop_collection_success
    assert data["message"] == "Collection dropped successfully"
E   assert "Collection '... successfully" == 'Collection d... successfully'
E
E     - Collection dropped successfully
E     + Collection 'geodocs' dropped successfully
E     ?            ++++++++++
_______________________________ TestStatisticsEndpoint.test_get_stats_success ________________________________
tests/test_api.py:384: in test_get_stats_success
    assert data["document_count"] == 150
E   KeyError: 'document_count'
____________________________ TestStatisticsEndpoint.test_get_stats_no_collection _____________________________
tests/test_api.py:396: in test_get_stats_no_collection
    assert data["document_count"] == 0
E   KeyError: 'document_count'
________________________________ TestStatisticsEndpoint.test_get_stats_error _________________________________
tests/test_api.py:407: in test_get_stats_error
    assert response.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
E   assert 200 == 500
E    +  where 200 = <Response [200 OK]>.status_code
E    +  and   500 = status.HTTP_500_INTERNAL_SERVER_ERROR
_______________________________ TestIntegration.test_upload_and_query_workflow _______________________________
tests/test_api.py:450: in test_upload_and_query_workflow
    assert upload_response.status_code == status.HTTP_200_OK
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
E    +  and   200 = status.HTTP_200_OK
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
___________________________ TestCUDACompatibility.test_reranking_gpu_compatibility ___________________________
/usr/lib/python3.12/unittest/mock.py:1387: in patched
    with self.decoration_helper(patched,
/usr/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
/usr/lib/python3.12/unittest/mock.py:1369: in decoration_helper
    arg = exit_stack.enter_context(patching)
/usr/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
/usr/lib/python3.12/unittest/mock.py:1442: in __enter__
    self.target = self.getter()
/usr/lib/python3.12/pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: module 'app.reranking' has no attribute 'torch'
_____________________________ TestSageMakerLLMClient.test_generate_client_error ______________________________
tests/test_sagemaker_integration.py:196: in test_generate_client_error
    assert "SageMaker API error" in result
E   AssertionError: assert 'SageMaker API error' in 'Error: Invalid request to SageMaker endpoint - Invalid endpoint name'
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    app.models.sagemaker_llm:sagemaker_llm.py:201 SageMaker ClientError [ValidationException]: Invalid endpoint name
_____________________________ TestSageMakerLLMClient.test_generate_general_error _____________________________
tests/test_sagemaker_integration.py:212: in test_generate_general_error
    assert "Error generating text" in result
E   AssertionError: assert 'Error generating text' in 'Error: Failed to generate response - Network error'
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    app.models.sagemaker_llm:sagemaker_llm.py:213 Unexpected error in SageMaker generation: Network error
____________________________ TestSageMakerLLMClient.test_test_connection_success _____________________________
tests/test_sagemaker_integration.py:236: in test_test_connection_success
    assert result["status"] == "success"
E   AssertionError: assert 'error' == 'success'
E
E     - success
E     + error
========================================== short test summary info ===========================================
FAILED tests/test_api.py::TestFileUpload::test_upload_pdf_success - assert 500 == 200
FAILED tests/test_api.py::TestFileUpload::test_upload_text_success - assert 500 == 200
FAILED tests/test_api.py::TestFileUpload::test_upload_empty_file - assert 503 == 400
FAILED tests/test_api.py::TestFileUpload::test_upload_processing_error - assert 'Error processing file' in "Error uploading document: [Errno 2] No such file or directory: '/app/d...
FAILED tests/test_api.py::TestQueryEndpoints::test_retrieve_success - KeyError: 'retrieval_count'
FAILED tests/test_api.py::TestCollectionManagement::test_drop_collection_success - assert "Collection '... successfully" == 'Collection d... successfully'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_success - KeyError: 'document_count'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_no_collection - KeyError: 'document_count'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_error - assert 200 == 500
FAILED tests/test_api.py::TestIntegration::test_upload_and_query_workflow - assert 500 == 200
FAILED tests/test_cuda_compatibility.py::TestCUDACompatibility::test_reranking_gpu_compatibility - AttributeError: module 'app.reranking' has no attribute 'torch'
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_client_error - AssertionError: assert 'SageMaker API error' in 'Error: Invalid request to SageMaker endpoint - Invalid e...
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_general_error - AssertionError: assert 'Error generating text' in 'Error: Failed to generate response - Network error'
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_test_connection_success - AssertionError: assert 'error' == 'success'
=========================== 14 failed, 41 passed, 1 skipped, 10 warnings in 9.14s ============================
[2025-07-04 14:38:44] WARNING: ‚ö†Ô∏è  Some unit tests failed - running individual test categories...
============================================ test session starts =============================================
platform linux -- Python 3.12.3, pytest-8.3.3, pluggy-1.6.0 -- /usr/bin/python
cachedir: .pytest_cache
rootdir: /app
plugins: anyio-4.9.0, asyncio-0.23.8, langsmith-0.3.45, timeout-2.3.1, mock-3.14.0, cov-5.0.0
asyncio: mode=Mode.STRICT
collected 29 items

tests/test_api.py::TestRootEndpoints::test_root_endpoint PASSED                                        [  3%]
tests/test_api.py::TestRootEndpoints::test_health_endpoint_healthy PASSED                              [  6%]
tests/test_api.py::TestRootEndpoints::test_health_endpoint_unhealthy PASSED                            [ 10%]
tests/test_api.py::TestFileUpload::test_upload_pdf_success FAILED                                      [ 13%]
tests/test_api.py::TestFileUpload::test_upload_text_success FAILED                                     [ 17%]
tests/test_api.py::TestFileUpload::test_upload_no_file PASSED                                          [ 20%]
tests/test_api.py::TestFileUpload::test_upload_empty_file FAILED                                       [ 24%]
tests/test_api.py::TestFileUpload::test_upload_processing_error FAILED                                 [ 27%]
tests/test_api.py::TestFileUpload::test_upload_kb_not_initialized PASSED                               [ 31%]
tests/test_api.py::TestQueryEndpoints::test_query_success PASSED                                       [ 34%]
tests/test_api.py::TestQueryEndpoints::test_query_no_results PASSED                                    [ 37%]
tests/test_api.py::TestQueryEndpoints::test_retrieve_success FAILED                                    [ 41%]
tests/test_api.py::TestQueryEndpoints::test_query_invalid_parameters PASSED                            [ 44%]
tests/test_api.py::TestQueryEndpoints::test_query_missing_query PASSED                                 [ 48%]
tests/test_api.py::TestQueryEndpoints::test_query_processing_error PASSED                              [ 51%]
tests/test_api.py::TestQueryEndpoints::test_query_kb_not_initialized PASSED                            [ 55%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_success FAILED                       [ 58%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_error PASSED                         [ 62%]
tests/test_api.py::TestCollectionManagement::test_drop_collection_kb_not_initialized PASSED            [ 65%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_success FAILED                               [ 68%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_no_collection FAILED                         [ 72%]
tests/test_api.py::TestStatisticsEndpoint::test_get_stats_error FAILED                                 [ 75%]
tests/test_api.py::TestErrorHandling::test_invalid_endpoint PASSED                                     [ 79%]
tests/test_api.py::TestErrorHandling::test_invalid_method PASSED                                       [ 82%]
tests/test_api.py::TestErrorHandling::test_malformed_json PASSED                                       [ 86%]
tests/test_api.py::TestIntegration::test_upload_and_query_workflow FAILED                              [ 89%]
tests/test_api.py::test_app_lifespan PASSED                                                            [ 93%]
tests/test_api.py::TestPerformance::test_health_endpoint_response_time PASSED                          [ 96%]
tests/test_api.py::TestPerformance::test_concurrent_queries PASSED                                     [100%]

================================================== FAILURES ==================================================
___________________________________ TestFileUpload.test_upload_pdf_success ___________________________________

self = <test_api.TestFileUpload object at 0x7f362134b380>
mock_kb = <MagicMock name='kb_instance' id='139870462632608'>, sample_pdf_file = '/tmp/tmpqt120gx8.pdf'

    @patch('app.main.kb_instance')
    def test_upload_pdf_success(self, mock_kb, sample_pdf_file):
        """Test successful PDF file upload."""
        mock_kb.add_file.return_value = None

        with open(sample_pdf_file, 'rb') as f:
            response = client.post(
                "/upload",
                files={"file": ("test.pdf", f, "application/pdf")}
            )

>       assert response.status_code == status.HTTP_200_OK
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code
E        +  and   200 = status.HTTP_200_OK

tests/test_api.py:142: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.pdf'
__________________________________ TestFileUpload.test_upload_text_success ___________________________________

self = <test_api.TestFileUpload object at 0x7f362134b470>
mock_kb = <MagicMock name='kb_instance' id='139870462495680'>, sample_text_file = '/tmp/tmppd9hhmy3.txt'

    @patch('app.main.kb_instance')
    def test_upload_text_success(self, mock_kb, sample_text_file):
        """Test successful text file upload."""
        mock_kb.add_file.return_value = None

        with open(sample_text_file, 'rb') as f:
            response = client.post(
                "/upload",
                files={"file": ("test.txt", f, "text/plain")}
            )

>       assert response.status_code == status.HTTP_200_OK
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code
E        +  and   200 = status.HTTP_200_OK

tests/test_api.py:162: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
___________________________________ TestFileUpload.test_upload_empty_file ____________________________________

self = <test_api.TestFileUpload object at 0x7f362134b800>

    def test_upload_empty_file(self):
        """Test upload with empty file."""
        response = client.post(
            "/upload",
            files={"file": ("empty.txt", b"", "text/plain")}
        )
>       assert response.status_code == status.HTTP_400_BAD_REQUEST
E       assert 503 == 400
E        +  where 503 = <Response [503 Service Unavailable]>.status_code
E        +  and   400 = status.HTTP_400_BAD_REQUEST

tests/test_api.py:177: AssertionError
________________________________ TestFileUpload.test_upload_processing_error _________________________________

self = <test_api.TestFileUpload object at 0x7f362134b890>
mock_kb = <MagicMock name='kb_instance' id='139870462660000'>, sample_text_file = '/tmp/tmpqfuxlgdr.txt'

    @patch('app.main.kb_instance')
    def test_upload_processing_error(self, mock_kb, sample_text_file):
        """Test upload when processing fails."""
        mock_kb.add_file.side_effect = Exception("Processing failed")

        with open(sample_text_file, 'rb') as f:
            response = client.post(
                "/upload",
                files={"file": ("test.txt", f, "text/plain")}
            )

        assert response.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
        data = response.json()
>       assert "Error processing file" in data["detail"]
E       assert 'Error processing file' in "Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'"

tests/test_api.py:194: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
__________________________________ TestQueryEndpoints.test_retrieve_success __________________________________

self = <test_api.TestQueryEndpoints object at 0x7f36213740e0>
mock_kb = <MagicMock name='kb_instance' id='139870452350656'>

    @patch('app.main.kb_instance')
    def test_retrieve_success(self, mock_kb):
        """Test successful document retrieval."""
        mock_documents = [
            {"text": "Document 1", "score": 0.9},
            {"text": "Document 2", "score": 0.8}
        ]
        mock_kb.retrieval.return_value = mock_documents

        query_data = {
            "query": "Test query",
            "k": 5,
            "expand_len": 512,
            "score_threshold": 0.5
        }

        response = client.post("/retrieve", json=query_data)
        assert response.status_code == status.HTTP_200_OK

        data = response.json()
        assert data["query"] == "Test query"
        assert len(data["documents"]) == 2
>       assert data["retrieval_count"] == 2
E       KeyError: 'retrieval_count'

tests/test_api.py:282: KeyError
___________________________ TestCollectionManagement.test_drop_collection_success ____________________________

self = <test_api.TestCollectionManagement object at 0x7f36213745f0>
mock_kb = <MagicMock name='kb_instance' id='139870453241696'>

    @patch('app.main.kb_instance')
    def test_drop_collection_success(self, mock_kb):
        """Test successful collection drop."""
        mock_kb.drop_collection.return_value = None

        response = client.delete("/collection")
        assert response.status_code == status.HTTP_200_OK

        data = response.json()
>       assert data["message"] == "Collection dropped successfully"
E       assert "Collection '... successfully" == 'Collection d... successfully'
E
E         - Collection dropped successfully
E         + Collection 'geodocs' dropped successfully
E         ?            ++++++++++

tests/test_api.py:346: AssertionError
_______________________________ TestStatisticsEndpoint.test_get_stats_success ________________________________

self = <test_api.TestStatisticsEndpoint object at 0x7f3621374c50>
mock_kb = <MagicMock name='kb_instance' id='139870448111728'>

    @patch('app.main.kb_instance')
    def test_get_stats_success(self, mock_kb):
        """Test successful statistics retrieval."""
        # Mock the vector store collection
        mock_collection = Mock()
        mock_collection.num_entities = 150
        mock_kb.vector_store.col = mock_collection

        response = client.get("/stats")
        assert response.status_code == status.HTTP_200_OK

        data = response.json()
        assert data["collection_name"] == MILVUS_COLLECTION
>       assert data["document_count"] == 150
E       KeyError: 'document_count'

tests/test_api.py:384: KeyError
____________________________ TestStatisticsEndpoint.test_get_stats_no_collection _____________________________

self = <test_api.TestStatisticsEndpoint object at 0x7f3621374dd0>
mock_kb = <MagicMock name='kb_instance' id='139870452643408'>

    @patch('app.main.kb_instance')
    def test_get_stats_no_collection(self, mock_kb):
        """Test statistics when collection doesn't exist."""
        mock_kb.vector_store.col = None

        response = client.get("/stats")
        assert response.status_code == status.HTTP_200_OK

        data = response.json()
>       assert data["document_count"] == 0
E       KeyError: 'document_count'

tests/test_api.py:396: KeyError
________________________________ TestStatisticsEndpoint.test_get_stats_error _________________________________

self = <test_api.TestStatisticsEndpoint object at 0x7f3621374f80>
mock_kb = <MagicMock name='kb_instance' id='139870448653648'>

    @patch('app.main.kb_instance')
    def test_get_stats_error(self, mock_kb):
        """Test statistics when an error occurs."""
        mock_kb.vector_store.col.num_entities = property(
            lambda self: (_ for _ in ()).throw(Exception("Stats error"))
        )

        response = client.get("/stats")
>       assert response.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
E       assert 200 == 500
E        +  where 200 = <Response [200 OK]>.status_code
E        +  and   500 = status.HTTP_500_INTERNAL_SERVER_ERROR

tests/test_api.py:407: AssertionError
_______________________________ TestIntegration.test_upload_and_query_workflow _______________________________

self = <test_api.TestIntegration object at 0x7f3621375970>
mock_kb = <MagicMock name='kb_instance' id='139870448112784'>, sample_text_file = '/tmp/tmpg1udxm3v.txt'

    @patch('app.main.kb_instance')
    def test_upload_and_query_workflow(self, mock_kb, sample_text_file):
        """Test complete workflow: upload file then query."""
        # Setup mocks
        mock_kb.add_file.return_value = None
        mock_documents = [{"text": "Sample content", "score": 0.9}]
        mock_kb.query.return_value = (mock_documents, "Response")

        # 1. Upload file
        with open(sample_text_file, 'rb') as f:
            upload_response = client.post(
                "/upload",
                files={"file": ("test.txt", f, "text/plain")}
            )
>       assert upload_response.status_code == status.HTTP_200_OK
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code
E        +  and   200 = status.HTTP_200_OK

tests/test_api.py:450: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    root:main.py:182 Error uploading document: [Errno 2] No such file or directory: '/app/data/uploads/test.txt'
============================================== warnings summary ==============================================
../usr/local/lib/python3.12/dist-packages/starlette/formparsers.py:12
  /usr/local/lib/python3.12/dist-packages/starlette/formparsers.py:12: PendingDeprecationWarning: Please use `import python_multipart` instead.
    import multipart

app/kb.py:20
  /app/app/kb.py:20: LangChainDeprecationWarning: Importing Milvus from langchain.vectorstores is deprecated. Please replace deprecated imports:

  >> from langchain.vectorstores import Milvus

  with new imports of:

  >> from langchain_community.vectorstores import Milvus
  You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
    from langchain.vectorstores import Milvus

../usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6
  /usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
    from pkg_resources import DistributionNotFound, get_distribution

<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

../usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323
../usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323
  /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

../usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111
  /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
    warnings.warn(

tests/test_api.py::TestErrorHandling::test_malformed_json
  /usr/local/lib/python3.12/dist-packages/httpx/_content.py:202: DeprecationWarning: Use 'content=<...>' to upload raw bytes/text content.
    warnings.warn(message, DeprecationWarning)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_api.py::TestFileUpload::test_upload_pdf_success - assert 500 == 200
FAILED tests/test_api.py::TestFileUpload::test_upload_text_success - assert 500 == 200
FAILED tests/test_api.py::TestFileUpload::test_upload_empty_file - assert 503 == 400
FAILED tests/test_api.py::TestFileUpload::test_upload_processing_error - assert 'Error processing file' in "Error uploading document: [Errno 2] No such file or directory: '/app/d...
FAILED tests/test_api.py::TestQueryEndpoints::test_retrieve_success - KeyError: 'retrieval_count'
FAILED tests/test_api.py::TestCollectionManagement::test_drop_collection_success - assert "Collection '... successfully" == 'Collection d... successfully'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_success - KeyError: 'document_count'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_no_collection - KeyError: 'document_count'
FAILED tests/test_api.py::TestStatisticsEndpoint::test_get_stats_error - assert 200 == 500
FAILED tests/test_api.py::TestIntegration::test_upload_and_query_workflow - assert 500 == 200
================================= 10 failed, 19 passed, 9 warnings in 7.72s ==================================
============================================ test session starts =============================================
platform linux -- Python 3.12.3, pytest-8.3.3, pluggy-1.6.0 -- /usr/bin/python
cachedir: .pytest_cache
rootdir: /app
plugins: anyio-4.9.0, asyncio-0.23.8, langsmith-0.3.45, timeout-2.3.1, mock-3.14.0, cov-5.0.0
asyncio: mode=Mode.STRICT
collected 8 items

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_pytorch_cuda_version PASSED              [ 12%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_tensorflow_gpu_access PASSED             [ 25%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_transformers_device_detection PASSED     [ 37%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_embeddings_gpu_compatibility SKIPPED     [ 50%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_reranking_gpu_compatibility FAILED       [ 62%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_model_cache_directories PASSED           [ 75%]
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_dependency_versions PASSED               [ 87%]
tests/test_cuda_compatibility.py::TestPerformanceWithGPU::test_tensor_operations_performance PASSED    [100%]

================================================== FAILURES ==================================================
___________________________ TestCUDACompatibility.test_reranking_gpu_compatibility ___________________________

args = (<test_cuda_compatibility.TestCUDACompatibility object at 0x7ec7b10780e0>,), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

/usr/lib/python3.12/unittest/mock.py:1387:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/usr/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
/usr/lib/python3.12/unittest/mock.py:1369: in decoration_helper
    arg = exit_stack.enter_context(patching)
/usr/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
/usr/lib/python3.12/unittest/mock.py:1442: in __enter__
    self.target = self.getter()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

name = 'app.reranking.torch.cuda'

    def resolve_name(name):
        """
        Resolve a name to an object.

        It is expected that `name` will be a string in one of the following
        formats, where W is shorthand for a valid Python identifier and dot stands
        for a literal period in these pseudo-regexes:

        W(.W)*
        W(.W)*:(W(.W)*)?

        The first form is intended for backward compatibility only. It assumes that
        some part of the dotted name is a package, and the rest is an object
        somewhere within that package, possibly nested inside other objects.
        Because the place where the package stops and the object hierarchy starts
        can't be inferred by inspection, repeated attempts to import must be done
        with this form.

        In the second form, the caller makes the division point clear through the
        provision of a single colon: the dotted name to the left of the colon is a
        package to be imported, and the dotted name to the right is the object
        hierarchy within that package. Only one import is needed in this form. If
        it ends with the colon, then a module object is returned.

        The function will return an object (which might be a module), or raise one
        of the following exceptions:

        ValueError - if `name` isn't in a recognised format
        ImportError - if an import failed when it shouldn't have
        AttributeError - if a failure occurred when traversing the object hierarchy
                         within the imported package to get to the desired object.
        """
        global _NAME_PATTERN
        if _NAME_PATTERN is None:
            # Lazy import to speedup Python startup time
            import re
            dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'
                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',
                                       re.UNICODE)

        m = _NAME_PATTERN.match(name)
        if not m:
            raise ValueError(f'invalid format: {name!r}')
        gd = m.groupdict()
        if gd.get('cln'):
            # there is a colon - a one-step import is all that's needed
            mod = importlib.import_module(gd['pkg'])
            parts = gd.get('obj')
            parts = parts.split('.') if parts else []
        else:
            # no colon - have to iterate to find the package boundary
            parts = name.split('.')
            modname = parts.pop(0)
            # first part *must* be a module/package.
            mod = importlib.import_module(modname)
            while parts:
                p = parts[0]
                s = f'{modname}.{p}'
                try:
                    mod = importlib.import_module(s)
                    parts.pop(0)
                    modname = s
                except ImportError:
                    break
        # if we reach this point, mod is the module, already imported, and
        # parts is the list of parts in the object hierarchy to be traversed, or
        # an empty list if just the module is wanted.
        result = mod
        for p in parts:
>           result = getattr(result, p)
E           AttributeError: module 'app.reranking' has no attribute 'torch'

/usr/lib/python3.12/pkgutil.py:528: AttributeError
============================================== warnings summary ==============================================
tests/test_cuda_compatibility.py:174
  /app/tests/test_cuda_compatibility.py:174: PytestUnknownMarkWarning: Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.performance

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_tensorflow_gpu_access
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_tensorflow_gpu_access
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_transformers_device_detection
  /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
    warnings.warn(

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_embeddings_gpu_compatibility
tests/test_cuda_compatibility.py::TestCUDACompatibility::test_reranking_gpu_compatibility
  /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

tests/test_cuda_compatibility.py::TestCUDACompatibility::test_dependency_versions
  /usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
    from pkg_resources import DistributionNotFound, get_distribution

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_cuda_compatibility.py::TestCUDACompatibility::test_reranking_gpu_compatibility - AttributeError: module 'app.reranking' has no attribute 'torch'
============================= 1 failed, 6 passed, 1 skipped, 7 warnings in 7.57s =============================
============================================ test session starts =============================================
platform linux -- Python 3.12.3, pytest-8.3.3, pluggy-1.6.0 -- /usr/bin/python
cachedir: .pytest_cache
rootdir: /app
plugins: anyio-4.9.0, asyncio-0.23.8, langsmith-0.3.45, timeout-2.3.1, mock-3.14.0, cov-5.0.0
asyncio: mode=Mode.STRICT
collected 19 items

tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_success PASSED [  5%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_with_credentials PASSED [ 10%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_boto3_missing PASSED [ 15%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_client_initialization_no_credentials PASSED [ 21%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_prepare_request_payload PASSED       [ 26%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_huggingface_format PASSED [ 31%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_dict_format PASSED    [ 36%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_parse_response_malformed_json PASSED [ 42%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_success PASSED              [ 47%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_client_error FAILED         [ 52%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_general_error FAILED        [ 57%]
tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_test_connection_success FAILED       [ 63%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_sagemaker_response_success PASSED [ 68%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_sagemaker_response_no_endpoint PASSED [ 73%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_llm_response_sagemaker_provider PASSED [ 78%]
tests/test_sagemaker_integration.py::TestSageMakerIntegration::test_generate_llm_response_openai_provider PASSED [ 84%]
tests/test_sagemaker_integration.py::TestSageMakerRAGIntegration::test_full_rag_query_with_sagemaker PASSED [ 89%]
tests/test_sagemaker_integration.py::TestSageMakerAPIIntegration::test_api_query_with_sagemaker PASSED [ 94%]
tests/test_sagemaker_integration.py::TestSageMakerAPIIntegration::test_api_query_sagemaker_not_configured PASSED [100%]

================================================== FAILURES ==================================================
_____________________________ TestSageMakerLLMClient.test_generate_client_error ______________________________

self = <test_sagemaker_integration.TestSageMakerLLMClient object at 0x7102ba2afbc0>
mock_boto_client = <MagicMock name='client' id='124256594656816'>

    @patch('app.models.sagemaker_llm.boto3.client')
    def test_generate_client_error(self, mock_boto_client):
        """Test handling of SageMaker client errors."""
        # Setup mock client with error
        mock_client = Mock()
        mock_boto_client.return_value = mock_client

        error_response = {
            "Error": {
                "Code": "ValidationException",
                "Message": "Invalid endpoint name"
            }
        }
        mock_client.invoke_endpoint.side_effect = ClientError(error_response, "InvokeEndpoint")

        # Test error handling
        client = SageMakerLLMClient("test-endpoint")
        result = client.generate("Test prompt")

>       assert "SageMaker API error" in result
E       AssertionError: assert 'SageMaker API error' in 'Error: Invalid request to SageMaker endpoint - Invalid endpoint name'

tests/test_sagemaker_integration.py:196: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    app.models.sagemaker_llm:sagemaker_llm.py:201 SageMaker ClientError [ValidationException]: Invalid endpoint name
_____________________________ TestSageMakerLLMClient.test_generate_general_error _____________________________

self = <test_sagemaker_integration.TestSageMakerLLMClient object at 0x7102ba2afcb0>
mock_boto_client = <MagicMock name='client' id='124256527671680'>

    @patch('app.models.sagemaker_llm.boto3.client')
    def test_generate_general_error(self, mock_boto_client):
        """Test handling of general errors during generation."""
        # Setup mock client with general error
        mock_client = Mock()
        mock_boto_client.return_value = mock_client
        mock_client.invoke_endpoint.side_effect = Exception("Network error")

        # Test error handling
        client = SageMakerLLMClient("test-endpoint")
        result = client.generate("Test prompt")

>       assert "Error generating text" in result
E       AssertionError: assert 'Error generating text' in 'Error: Failed to generate response - Network error'

tests/test_sagemaker_integration.py:212: AssertionError
--------------------------------------------- Captured log call ----------------------------------------------
ERROR    app.models.sagemaker_llm:sagemaker_llm.py:213 Unexpected error in SageMaker generation: Network error
____________________________ TestSageMakerLLMClient.test_test_connection_success _____________________________

self = <test_sagemaker_integration.TestSageMakerLLMClient object at 0x7102ba2af8c0>
mock_boto_client = <MagicMock name='client' id='124256527666784'>

    @patch('app.models.sagemaker_llm.boto3.client')
    def test_test_connection_success(self, mock_boto_client):
        """Test successful connection test."""
        # Setup mock client
        mock_client = Mock()
        mock_boto_client.return_value = mock_client

        # Mock successful test response
        mock_response = {
            "Body": Mock()
        }
        mock_response["Body"].read.return_value = json.dumps([{
            "generated_text": "Connection test successful"
        }]).encode("utf-8")

        mock_client.invoke_endpoint.return_value = mock_response

        # Test connection
        client = SageMakerLLMClient("test-endpoint")
        result = client.test_connection()

>       assert result["status"] == "success"
E       AssertionError: assert 'error' == 'success'
E
E         - success
E         + error

tests/test_sagemaker_integration.py:236: AssertionError
============================================== warnings summary ==============================================
app/kb.py:20
  /app/app/kb.py:20: LangChainDeprecationWarning: Importing Milvus from langchain.vectorstores is deprecated. Please replace deprecated imports:

  >> from langchain.vectorstores import Milvus

  with new imports of:

  >> from langchain_community.vectorstores import Milvus
  You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
    from langchain.vectorstores import Milvus

../usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6
  /usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
    from pkg_resources import DistributionNotFound, get_distribution

<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

<frozen importlib._bootstrap>:488
  <frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.

../usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323
../usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323
  /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

../usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111
  /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
    warnings.warn(

tests/test_sagemaker_integration.py::TestSageMakerAPIIntegration::test_api_query_with_sagemaker
  /usr/local/lib/python3.12/dist-packages/starlette/formparsers.py:12: PendingDeprecationWarning: Please use `import python_multipart` instead.
    import multipart

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_client_error - AssertionError: assert 'SageMaker API error' in 'Error: Invalid request to SageMaker endpoint - Invalid e...
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_generate_general_error - AssertionError: assert 'Error generating text' in 'Error: Failed to generate response - Network error'
FAILED tests/test_sagemaker_integration.py::TestSageMakerLLMClient::test_test_connection_success - AssertionError: assert 'error' == 'success'
================================== 3 failed, 16 passed, 8 warnings in 7.53s ==================================
[2025-07-04 14:39:13] SUCCESS: ‚úÖ Phase 11 completed: Unit tests executed
[2025-07-04 14:39:13] üéØ Phase 12: Comprehensive Test Results Report

============================================================
üéâ GeoGPT-RAG Enhanced Pipeline Test Summary
============================================================
Environment: LOCAL
CUDA Version: 12.8.0
Base Image: nvidia/cuda:12.8.0-cudnn-devel-ubuntu24.04
Test Execution Time: Fri Jul  4 02:39:13 PM UTC 2025

üìä Test Results Summary:
========================
‚úÖ Tests Passed: 10
‚ùå Tests Failed: 10
üìà Success Rate: 50%

üìã Detailed Test Results:
=========================
   ‚úÖ Docker Containers
   ‚úÖ Dependencies
   ‚úÖ CUDA Compatibility
   ‚úÖ Health Endpoint
   ‚úÖ Root Endpoint
   ‚ùå SageMaker LLM Generation: No documents in KB
   ‚úÖ SageMaker Direct Connection
   ‚ùå Document Upload: HTTP 500
   ‚ùå Embedding Quality:
   ‚ùå Vector Store Operations:
   ‚ùå Reranking Functionality:
   ‚ùå Document Processing:
   ‚úÖ Performance Benchmarks
   ‚úÖ Malformed JSON Handling
   ‚úÖ Missing Fields Handling
   ‚ùå Long Query Handling: HTTP 500
   ‚úÖ Invalid File Handling
   ‚ùå API Unit Tests:
   ‚ùå CUDA Unit Tests:
   ‚ùå SageMaker Unit Tests:

üñ•Ô∏è  System Status:
==================
‚úÖ Docker Containers: Running
‚úÖ API Endpoints: Operational
üöÄ GPU Access: Yes

üì¶ Key Dependencies:
/usr/local/lib/python3.12/dist-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import DistributionNotFound, get_distribution
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
   Python: 3.12.3
   PyTorch: 2.4.0+cu121
   pymilvus: 2.4.10
   transformers: 4.53.0

============================================================
[2025-07-04 14:39:18] ERROR: ‚ùå GeoGPT-RAG Pipeline: SIGNIFICANT ISSUES DETECTED