# =====================================================================================
# GeoGPT-RAG Production Environment Configuration for EC2 g5.xlarge
# Optimized for AWS deployment with IAM role-based authentication
# =====================================================================================

# üöÄ Application Configuration
APP_NAME=GeoGPT-RAG
APP_VERSION=1.0.0
ENVIRONMENT=production



# AWS Configuration (IAM Role-based - ACTIVE)
AWS_REGION=us-east-1
AWS_DEFAULT_REGION=us-east-1


# üîê Alternative: Explicit AWS Credentials (NOT NEEDED - IAM role active)
# AWS_ACCESS_KEY_ID=your_aws_access_key_here
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here

# ü§ñ LLM Configuration - SageMaker (Primary)
LLM_PROVIDER=sagemaker
SAGEMAKER_ENDPOINT_NAME=GeoGPT-R1-Sagemaker-Endpoint
SAGEMAKER_REGION=us-east-1

# üìä Vector Database Configuration - Zilliz Cloud
ZILLIZ_URI=https://in03-0beed7b5287844d.serverless.gcp-us-west1.cloud.zilliz.com
ZILLIZ_TOKEN=affa13223a768e6e16b4e2bebf1e3f95b7b9085814d1407470c10922c7469d459cf523c189e99e24a20a1146976edd1a808d34fc
MILVUS_COLLECTION=geodocs

# üéØ Model Configuration
EMBED_MODEL=GeoGPT-Research-Project/GeoEmbedding
RERANK_MODEL=GeoGPT-Research-Project/GeoReranker
BERT_PATH=bert-base-uncased

# üöÄ Performance Settings (Optimized for g5.xlarge)
# =====================================================================================
# GPU Configuration (A10G - 24GB VRAM)
EMBEDDING_DEVICE=cuda
RERANKING_DEVICE=cuda
TEXT_SPLITTER_DEVICE=cuda

# üìà Batch Sizes (Optimized for A10G 24GB VRAM)
EMBEDDING_BATCH_SIZE=32
RERANKING_BATCH_SIZE=32
VEC_RECALL_NUM=128
MAX_SIZE=512

# üîß Model Optimizations
EMBEDDING_FP16=true
RERANKING_FP16=true
PRELOAD_MODELS=true

# üíæ Memory Management (g5.xlarge: 16GB RAM)
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2048,expandable_segments:True
TOKENIZERS_PARALLELISM=false
OMP_NUM_THREADS=4
CUDA_LAUNCH_BLOCKING=0

# üî• GPU Optimizations (A10G specific)
TORCH_CUDNN_V8_API_ENABLED=1
TORCH_CUDNN_BENCHMARK=1

# üìÅ Cache Configuration
TRANSFORMERS_CACHE=/app/.cache/transformers
HF_HOME=/app/.cache/huggingface
TORCH_HOME=/app/.cache/torch
NLTK_DATA=/usr/local/share/nltk_data

# ‚öôÔ∏è RAG Pipeline Settings
# =====================================================================================
# Retrieval Configuration
TOP_K=5
SCORE_THRESHOLD=0.5
EXPAND_RANGE=1000

# Text Processing
MAX_CONTENT_LENGTH=10000
CHUNK_OVERLAP=100

# üìù Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# üåê API Configuration
# =====================================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# Request Timeouts (in seconds)
REQUEST_TIMEOUT=300
MODEL_LOAD_TIMEOUT=900

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_UPLOAD_SIZE=50MB

# üè• Health Check Configuration
HEALTH_CHECK_TIMEOUT=60
STARTUP_TIMEOUT=300

# üîç Monitoring & Observability
# =====================================================================================
# CloudWatch Integration (optional)
ENABLE_CLOUDWATCH=false
CLOUDWATCH_LOG_GROUP=GeoGPT-RAG-Logs
CLOUDWATCH_LOG_STREAM=production

# Metrics Collection
ENABLE_METRICS=true
METRICS_PORT=9090

# ‚ö° Production Optimizations
# =====================================================================================
# Uvicorn Settings
UVICORN_WORKERS=1
UVICORN_LOOP=uvloop
UVICORN_HTTP=httptools
UVICORN_BACKLOG=2048
UVICORN_MAX_REQUESTS=1000
UVICORN_TIMEOUT_KEEP_ALIVE=65
UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=30

# üîê Security Headers
CORS_ORIGINS=*
CORS_METHODS=GET,POST,PUT,DELETE
CORS_HEADERS=*

# Content Security
MAX_REQUEST_SIZE=100MB
ALLOWED_EXTENSIONS=pdf,txt,md,docx

# üìä Database Connection Pooling
CONNECTION_POOL_SIZE=10
CONNECTION_TIMEOUT=30

# üöÄ Deployment Metadata
DEPLOYMENT_TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
GIT_COMMIT_HASH=latest
INSTANCE_TYPE=g5.xlarge
INSTANCE_ID=i-0a3b0271a4e3ea64f
INSTANCE_PUBLIC_IP=13.222.7.253
INSTANCE_PRIVATE_IP=172.31.68.27
IAM_ROLE_NAME=GeoGPT-Custom-Role-EC2

